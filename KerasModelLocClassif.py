# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py:percent
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.2'
#       jupytext_version: 0.8.6
#   kernelspec:
#     display_name: Python 3
#     language: python
#     name: python3
# ---

"""KerasModelLocClassif.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ct6-QmftnH70Gm_lSN1pRbBeYd9_fN8R

# Date Location and Multiclass-Classifcation (Keras)

Main steps:

 1. Get raw data (COCO): 5000 images 
 2. ImageDataLocationGenerator class and fit_generator
 3. CNN
 4. fit_generator, which generates data on-the-fly
 5. Save in Google Drive
"""
# %%
import pickle
def save_obj_as_pkl(obj, name="model/obj.pkl"):
    with open(name, 'wb') as f:
        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)

# Colab setup
import sys
def is_colab_notebook():
    return 'google.colab' in sys.modules

# Mount your Drive drive. This is needed to save results to your Google Drive
if is_colab_notebook():
    from google.colab import drive
    drive.mount('/content/gdrive')

def plot_losses(m, save_path='model/plot_losses.png', fit_number = ""):
    s = m
    plt.figure(figsize=(13, 15))
    plt.subplot(311)
    plt.plot(s['epoch'], s['loss'], linestyle='dashed')
    plt.plot(s['epoch'], s['val_loss'])
    plt.title("Fit: {} - loss - train/valid".format(fit_number))
    plt.legend()

    plt.subplot(312)
    plt.plot(s['epoch'], s['xywh_loss'], linestyle='dashed')
    plt.plot(s['epoch'], s['val_xywh_loss'])
    plt.title("Fit: {} - xywh_loss - train/valid".format(fit_number))
    plt.legend()

    plt.subplot(313)
    losses = ['d0_loss', 'd1_loss', 'd2_loss', 'd3_loss', 'd4_loss', 'd5_loss']
    for a in losses:
        plt.plot(s['epoch'], s[a], linestyle='dashed')
        plt.plot(s['epoch'], s['val_' + a])
    plt.title("Fit: {} - d0-d5_loss - train/valid".format(fit_number))
    plt.legend()
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path)
        
        
def plot_measures(m, save_path='model/plot_measures.png', fit_number = ""):
    s = m
    plt.figure(figsize=(13, 15))        
    plt.subplot(211)
    plt.plot(s['epoch'], s['xywh_mean_squared_error'], linestyle='dashed')
    plt.plot(s['epoch'], s['val_xywh_mean_squared_error'])
    plt.title("Fit: {} - xywh_mse - train/valid".format(fit_number))
    #plt.yscale('log')
    plt.legend()
    
    plt.subplot(212)
    accs = ['d0_acc', 'd1_acc', 'd2_acc', 'd3_acc', 'd4_acc', 'd5_acc']
    for a in accs:
        plt.plot(s['epoch'], s[a], linestyle='dashed')
        plt.plot(s['epoch'], s['val_' + a])
    plt.title("Fit: {} - d0-d5_accuracy - train/valid".format(fit_number))
    #plt.yscale('log')
    plt.legend()
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)

# %%
!cp -f /content/gdrive/My\ Drive/date_datetection/TrainingDataGeneration.py TrainingDataGeneration.py 
!cp -rf /content/gdrive/My\ Drive/date_datetection/tools tools
!cp -rf /content/gdrive/My\ Drive/date_datetection/pb_schluessel.txt pb_schluessel.txt
!ls tools

# %%
!ls

# %%
!pip install -q pushbullet.py

# %%
from pushbullet import Pushbullet
f = open('pb_schluessel.txt','r')
key = f.read()
f.close()
pb = Pushbullet(key)

# %%
from PIL import Image, ImageDraw
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from datetime import datetime

# %%
from IPython.display import display

# %%
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout
from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard
from keras.utils import plot_model
from keras import backend as K

# %%
K.tensorflow_backend._get_available_gpus()

from TrainingDataGeneration import DateImageGenerator
from tools import basic, draw

# %%
# Create folders to store model in
os.makedirs("model", exist_ok=True)
#os.makedirs("model/weights", exist_ok=True)

# %%
# Download data and fonts
basic.get_coco_dataset()
fontnames = basic.get_dseg_fonts()

# %%
"""### Checkpoint"""

#filepath="model/weights/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5"
#checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=True)
logger = CSVLogger('model/measures.csv', append=True, separator=';')

#batch_size = 100
#tbcallback = TensorBoard(log_dir='model/tbc', histogram_freq=1,
#                         write_graph=True,
#                         write_grads=False,
#                         batch_size=batch_size,
#                         write_images=False)
#callbacks_list = [checkpoint, logger]
#callbacks_list = [logger, tbcallback]
callbacks_list = [logger]

# %% [markdown]
"""### Init DateImageGenerator"""

# %%
#
# Set parameters for image generation:
#
bg_image_path = os.path.expanduser("val2017/")
#target_size = (200, 100)
target_size = (100, 100)
#font_lettersize_range = (10, 16)
font_lettersize_range = (10, 12)
h = (40/360, 100/360) 
s = (80/100, 100/100)
v = (80/100, 100/100)

# image generator
gen = DateImageGenerator(bg_image_path=bg_image_path, target_size=target_size,
    font_paths=fontnames, font_lettersize_range=font_lettersize_range,
    h=h, s=s, v=v)

mains, font_dict, noise_dict, misc_dict = gen.sample_localisation(realistic_date=False)

b_xywh = mains['bounding_box']
pos = misc_dict['position_upperleft_corner']

# Try it out (generates one sample).
#img, date, center, font, font_lettersize, font_width_height, position, color, rotation, is_vintage, blur_value, noise_saltpepper_value, noise_gauss_value, img_original, img_original_cropped = gen.sample(add_point_at_target=False)
lower_right = (pos[0] + b_xywh[2], pos[1] + b_xywh[3])
#print("date: {}, center: {}, font_width_height: {}, position: {}, color: {}, rotation: {}, is_vintage: {}, blur_value: {}, noise_sp_value: {}, noise_gauss_value: {}".format(date, center, font_width_height, position, color, rotation, is_vintage, blur_value, noise_saltpepper_value, noise_gauss_value))

print("Image with date: <{}> | <{}> | <{}>".format(mains['date_iso'], misc_dict['date_formated'], mains['digits']))
display(mains['img'])
print("Image with date and box around it:")
sol = draw.draw_box(mains['img'], pos, lower_right, fill=0, width=3)
display(draw.draw_box(sol, pos, lower_right, fill=255, width=1))

# %%
def localisation_and_multiclass_generator(batch_size=100, normalize=True):
    """generator function which will passed to keras' fit_generation function.
    This function makes use of the ImageDateLocationGenerator class."""
    batch_x = np.zeros((batch_size, target_size[1], target_size[0], 3))
    outb = np.zeros((batch_size, 4))
    out0 = np.zeros((batch_size, 11))
    out1 = np.zeros((batch_size, 11))
    out2 = np.zeros((batch_size, 11))
    out3 = np.zeros((batch_size, 11))
    out4 = np.zeros((batch_size, 11))
    out5 = np.zeros((batch_size, 11))
    outs = [out0, out1, out2, out3, out4, out5]
    while True:
        for i in range(batch_size):
            mains, _, _, _ = gen.sample_localisation(realistic_date=True)
            
            # features
            x = np.array(mains['img'])            
            if normalize:
                x = x/255
            batch_x[i] = x
            #print(mains['digits'])
            # targets
            outb[i] = mains['bounding_box_relative']
            for j, d in enumerate(mains['digits']):
                if d == " ":
                    d = 10
                d = int(d)
                outs[j][i, d] = 1
        
        batch_list_y = [outb] + outs
        yield batch_x, batch_list_y

# %%
"""%%time
# ### Generate Validation Data

# generate validation data using the generator function. Returns a tuple (x_val, y_val).
if is_colab_notebook():
    valid_generator = localisation_and_multiclass_generator(batch_size=1000, normalize=True)
    valid = next(valid_generator)
else:
    valid_generator = localisation_and_multiclass_generator(batch_size=2, normalize=True)
    valid = next(valid_generator)

def keras2pil(x):
    '''img_keras with shape like (100,200,3) to img_pil'''
    return Image.fromarray(np.uint8(x*255))
"""

#valid[0][0].shape

#keras2pil(valid[0][0])

#valid[1]

# %%
# Check if GPU
K.tensorflow_backend._get_available_gpus()

# %% [markdown]
"""#### Build model"""

# %%
# # Model
input = Input(name='data_input', shape=(target_size[1], target_size[0], 3))

with K.name_scope('convlayer1'):
    x = Conv2D(20, (3, 3), activation="elu", padding="same", name="conv1")(input)
    x = BatchNormalization(name="bn1")(x)
    x = MaxPooling2D((2, 2), padding="same", name="maxpool1")(x)

with K.name_scope('convlayer2'):
    x = Conv2D(30, (3, 3), activation="elu", padding="same", name="conv2")(x)
    x = BatchNormalization(name="bn2")(x)
    x = MaxPooling2D((2, 2), padding="same", name="maxpool2")(x)

with K.name_scope('convlayer3'):
    x = Conv2D(40, (3, 3), activation="elu", padding="same", name="conv3")(x)
    x = BatchNormalization(name="bn3")(x)
    x = MaxPooling2D((2, 2), padding="same", name="maxpool3")(x)

with K.name_scope('convlayer4'):
    x = Conv2D(50, (3, 3), activation="elu", padding="same", name="conv4")(x)
    x = BatchNormalization(name="bn4")(x)
    x = MaxPooling2D((2, 2), padding="same", name="maxpool4")(x)
    
with K.name_scope('convlayer5'):
    x = Conv2D(25, (1, 1), activation="elu", padding="same", name="conv5")(x)
    x = BatchNormalization(name="bn5")(x)
    x = MaxPooling2D((2, 2), padding="same", name="maxpool5")(x)

x = Flatten(name='flatten')(x)

#with K.name_scope('dense1'):
#x = Dense(units=100, activation="elu", name="dense1")(x)

#with K.name_scope('dense2'):
#x = Dense(units=100, activation="elu", name="dense2")(x)
    
#with K.name_scope('dense3'):
#x = Dense(units=100, activation="elu", name="dense3")(x)
    
# Seperate final layers

#with K.name_scope('dense_regr'):
x_regr = Dense(units= 64, activation="elu", name="dense_regr1")(x)  
x_regr = Dense(units= 32, activation="elu", name="dense_regr2")(x_regr)  
    
#with K.name_scope('dense_classif'):
x_classif = Dense(units=256, activation="elu", name="dense_classif1")(x)
x_classif = Dense(units=128, activation="elu", name="dense_classif2")(x_classif)

# Output layers

with K.name_scope('out_regr'):
    outb = Dense(name="xywh", activation="sigmoid", units=4)(x_regr)

with K.name_scope('out_classif'):
    out0 = Dense(name="d0", activation="softmax", units=11)(x_classif)
    out1 = Dense(name="d1", activation="softmax", units=11)(x_classif)
    out2 = Dense(name="d2", activation="softmax", units=11)(x_classif)
    out3 = Dense(name="d3", activation="softmax", units=11)(x_classif)
    out4 = Dense(name="d4", activation="softmax", units=11)(x_classif)
    out5 = Dense(name="d5", activation="softmax", units=11)(x_classif)

outs = [outb, out0, out1, out2, out3, out4, out5]

if 'model' in locals():
    del model
    print("Old model removed.")
model = Model(inputs=input, outputs=outs)

# %%
model.summary()

# %%
try:
    plot_model(model, to_file='model/model.png')
except:
    print("Cannot print model.")

# %%
losses = {
    "xywh": "mae",
    "d0": "categorical_crossentropy",
    "d1": "categorical_crossentropy",
    "d2": "categorical_crossentropy",
    "d3": "categorical_crossentropy",
    "d4": "categorical_crossentropy",
    "d5": "categorical_crossentropy",
}
my_metrics={
    'xywh': 'mse',
    'd0': 'accuracy', 
    'd1': 'accuracy', 
    'd2': 'accuracy', 
    'd3': 'accuracy', 
    'd4': 'accuracy', 
    'd5': 'accuracy'
}

# %% 
# Fitting
DEBUG = False

if DEBUG:
    batch_size = 30
    steps_per_epoch = 3
    epochs1 = 4
    epochs2 = 8
elif is_colab_notebook():
    batch_size = 60 
    steps_per_epoch = 99
    epochs1 = 50 #20
    epochs2 = 150
else:
    batch_size = 60
    steps_per_epoch = 35
    epochs1 = 10
    epochs2 = 10
print("Debug mode is: {}".format(DEBUG))
print("That are {:,} observations in total.".format(batch_size * steps_per_epoch * (epochs2) ))

# %% [markdown]
"""## Fitting 1"""
# %% 
now_start_1 = datetime.now()
#loss_weights = {"xywh": 10.0, "d0": .1, "d1": .1, "d2": .1, "d3": .1, "d4": .1, "d5": .1}
loss_weights = {"xywh": 0.0, "d0": .1, "d1": .1, "d2": .1, "d3": .1, "d4": .1, "d5": .1}
model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights, metrics=my_metrics)

print("Train fresh model.")
print("Starting at {} UTC".format(str(now_start_1)))
history_1 = model.fit_generator(localisation_and_multiclass_generator(batch_size=batch_size), 
                                  steps_per_epoch=steps_per_epoch, 
                                  epochs=epochs1,
                                  validation_data=valid, 
                                  callbacks=callbacks_list)
model.save('model/model_1.h5')
save_obj_as_pkl(history_1, name="model/history_1.pkl")
now_end_1 = datetime.now()
# %% [markdown]
"""##### Plot"""
# %%
try:
    m1 = pd.DataFrame(history_1.history).reset_index().rename(columns={'index' : 'epoch'})
    plot_losses(m1, "model/plot_losses_1.png", "1")
    plot_measures(m1, "model/plot_measures_1.png", "1")
    
    # pushbullet
    push = pb.push_note("KerasModelLocClassif {}".format(now_start_1.strftime("%Y-%m-%d (%A)")), 
                        "Fit 1\nStarted at {}\nEnded at {}\nDuration {}".format(now_start_1, now_end_1, now_end_1 - now_start_1))
    # losses
    with open("model/plot_losses_1.png", "rb") as pic:
        file_data = pb.upload_file(pic, "plot_losses_1.jpg")
    push = pb.push_file(**file_data)
    # measures
    with open("model/plot_measures_1.png", "rb") as pic:
        file_data = pb.upload_file(pic, "plot_measures_1.jpg")
    push = pb.push_file(**file_data)
except:
    print("Plot does not work.")

# %% [markdown]
"""##### Save"""
# %%
if is_colab_notebook():
    drive_path="/content/gdrive/My Drive/date_detection_models/model_lc_"
    date = datetime.now().strftime('%Y%m%d')
    save_path = drive_path + date + "_1B"
    print(save_path)
    basic.cp('model', save_path)

# %% [markdown]
"""## Fitting 2"""
# %%
now_start_2 = datetime.now()
loss_weights = {"xywh": 1., "d0": 1., "d1": 1., "d2": 1., "d3": 1., "d4": 1., "d5": 1.}
model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights, metrics=my_metrics)

print("Starting at {}".format(str(now_start_2)))
history_2 = model.fit_generator(localisation_and_multiclass_generator(batch_size=batch_size), 
                                  steps_per_epoch=steps_per_epoch, 
                                  epochs=epochs2,
                                  validation_data=valid, 
                                  callbacks=callbacks_list,
                             initial_epoch=epochs1)
model.save('model/model_2.h5')
save_obj_as_pkl(history_2, name="model/history_2.pkl")
now_end_2 = datetime.now()

# %% [markdown]
"""##### Plot"""
# %%
try:
    m2 = pd.DataFrame(history_2.history).reset_index().rename(columns={'index' : 'epoch'})
    plot_losses(m2, "model/plot_losses_2.png", "2")
    plot_measures(m2, "model/plot_measures_2.png", "2")
    # pushbullet
    push = pb.push_note("KerasModelLocClassif {}".format(now_start_1.strftime("%Y-%m-%d (%A)")),
                        "Fit 2\nStarted at {}\nEnded at {}\nDuration {}".format(now_start_2, now_end_2, now_end_2 - now_start_2))
    # losses
    with open("model/plot_losses_2.png", "rb") as pic:
        file_data = pb.upload_file(pic, "plot_losses_2.jpg")
    push = pb.push_file(**file_data)
    # measures
    with open("model/plot_measures_2.png", "rb") as pic:
        file_data = pb.upload_file(pic, "plot_measures_2.jpg")
    push = pb.push_file(**file_data)
except:
    print("Plot does not work.")

# %% [markdown]
"""##### Save"""
# %% 
if is_colab_notebook():
    drive_path="/content/gdrive/My Drive/date_detection_models/model_lc_"
    date = datetime.now().strftime('%Y%m%d')
    save_path = drive_path + date + "_2B"
    print(save_path)
    basic.cp('model', save_path)
# %% [markdown]
"""Notify"""
# %% 
try:
    push = pb.push_note("KerasModelLocClassif {}".format(now_start_1.strftime("%Y-%m-%d (%A)")),
                        "Total\nStarted at {}\nEnded at {}\nDuration {}".format(now_start_1, now_end_2, now_end_2 - now_start_1))
except:
    print("Did not work.")

